<!DOCTYPE HTML>
<html>
 <head>
  <meta charset="utf-8"/>
  <title>
   Made with Remarkable!
  </title>
  <link href="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/styles/github.min.css" rel="stylesheet"/>
  <style type="text/css">
   body {
	font-family: "Avenir Next", Helvetica, Arial, sans-serif;
	padding:1em;
	margin:auto;
	max-width:42em;
	background:#fefefe;
}

h1, h2, h3, h4, h5, h6 {
	font-weight: bold;
}

h1 {
	color: #000000;
	font-size: 28pt;
}

h2 {
	border-bottom: 1px solid #CCCCCC;
	color: #000000;
	font-size: 24px;
}

h3 {
	font-size: 18px;
}

h4 {
	font-size: 16px;
}

h5 {
	font-size: 14px;
}

h6 {
	color: #777777;
	background-color: inherit;
	font-size: 14px;
}

hr {
	height: 0.2em;
	border: 0;
	color: #CCCCCC;
	background-color: #CCCCCC;
}

p, blockquote, ul, ol, dl, li, table, pre {
	margin: 15px 0;
}

a, a:visited {
	color: #4183C4;
	background-color: inherit;
	text-decoration: none;
}

#message {
	border-radius: 6px;
	border: 1px solid #ccc;
	display:block;
	width:100%;
	height:60px;
	margin:6px 0px;
}

button, #ws {
	font-size: 10pt;
	padding: 4px 6px;
	border-radius: 5px;
	border: 1px solid #bbb;
	background-color: #eee;
}

code, pre, #ws, #message {
	font-family: Monaco;
	font-size: 10pt;
	border-radius: 3px;
	background-color: #F8F8F8;
	color: inherit;
}

code {
	border: 1px solid #EAEAEA;
	margin: 0 2px;
	padding: 0 5px;
}

pre {
	border: 1px solid #CCCCCC;
	overflow: auto;
	padding: 4px 8px;
}

pre > code {
	border: 0;
	margin: 0;
	padding: 0;
}

#ws { background-color: #f8f8f8; }

.send { color:#77bb77; }
.server { color:#7799bb; }
.error { color:#AA0000; }
  </style>
 </head>
 <body>
  <h1 id="enron-fraud-detection">
   Enron fraud detection
  </h1>
  <h2 id="machine-learning-application">
   Machine Learning Application
  </h2>
  <h2 id="introduction">
   Introduction
  </h2>
  <p>
   This project is an application of
   <strong>
    machine learning
   </strong>
   for identifying persons that were involved in fraud at Enron. Machine learning can be used to detect those persons by investigating financial and email data of Enron employees, to find patterns
  </p>
  <p>
   Enron is a case of large scale corporate fraud in USA. During prosecution, the court decided to make public the financial data and also the emails. Enron executives decided to destroy a lot of documents while they were in prosecution. This fact may have contributed to the decision of the court to make the emails public.
  </p>
  <h2 id="investigation">
   Investigation
  </h2>
  <h3 id="loading-data">
   Loading data
  </h3>
  <p>
   The first step is loading the data and playing with it to understand the structure. I usually do this in a console. For this project the provided pickle file contains a dictionary, with the keys as strings containting the names of enron employees, and the values as dictionaries that contain some features.
  </p>
  <p>
   <strong>
    Number of elements:
   </strong>
   146
   <br/>
   <strong>
    Number of pois:
   </strong>
   18
  </p>
  <p>
   Actually, there were 35 persons involved in fraud, but the data set we have available only contains about half of them. This may be a problem, the number of examples of persons involved in fraud is very small, and it will be very hard to find meaningful patterns.
   <br/>
   We may have biased results. Any investigation we perform will be incomplete, and most likely biased (unless the people missing would be randomly selected, such that the sample we have is statistically representative, but this is unlikely due to the very limited examples).
  </p>
  <p>
   For a machine learning project, there’s not much difference between 18 and 35 data points. This dataset is definitely small, and hence difficult to asses the accuracy.
  </p>
  <p>
   <strong>
    Features available:
   </strong>
   21
  </p>
  <h3 id="selecting-features">
   Selecting features
  </h3>
  <p>
   In order to select the most useful features, I wanted to see what features have missing values, and how many missing values are there in each feature.
  </p>
  <p>
   Here’s my result:
  </p>
  <table>
   <thead>
    <tr>
     <th>
      Feature name
     </th>
     <th>
      Percent of non-Nan
     </th>
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>
      <font color="green">
       total_stock_value
      </font>
     </td>
     <td>
      <code>
       0.868965517241
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       total_payments
      </font>
     </td>
     <td>
      <code>
       0.862068965517
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       restricted_stock
      </font>
     </td>
     <td>
      <code>
       0.758620689655
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       exercised_stock_options
      </font>
     </td>
     <td>
      <code>
       0.703448275862
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       salary
      </font>
     </td>
     <td>
      <code>
       0.655172413793
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       expenses
      </font>
     </td>
     <td>
      <code>
       0.655172413793
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       other
      </font>
     </td>
     <td>
      <code>
       0.641379310345
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       to_messages
      </font>
     </td>
     <td>
      <code>
       0.593103448276
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       shared_receipt_with_poi
      </font>
     </td>
     <td>
      <code>
       0.593103448276
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       from_messages
      </font>
     </td>
     <td>
      <code>
       0.593103448276
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       from_poi_to_this_person
      </font>
     </td>
     <td>
      <code>
       0.593103448276
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       from_this_person_to_poi
      </font>
     </td>
     <td>
      <code>
       0.593103448276
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       bonus
      </font>
     </td>
     <td>
      <code>
       0.565517241379
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       long_term_incentive
      </font>
     </td>
     <td>
      <code>
       0.455172413793
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       deferred_income
      </font>
     </td>
     <td>
      <code>
       0.337931034483
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       deferral_payments
      </font>
     </td>
     <td>
      <code>
       0.268965517241
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       restricted_stock_deferred
      </font>
     </td>
     <td>
      <code>
       0.124137931034
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       director_fees
      </font>
     </td>
     <td>
      <code>
       0.11724137931
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       loan_advances
      </font>
     </td>
     <td>
      <code>
       0.0275862068966
      </code>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   For now I’ll select only the features that have at least 50% of values filled (non-NaN values), so the
   <font color="green">
    green
   </font>
   ones I selected for further investigation. Later I may slect from those the features that have the best predicting power.
  </p>
  <h3 id="outliers">
   Outliers
  </h3>
  <p>
   Rather than trying to guess on what features the outliers may be observed, I decided to use PCA for this. If a point in our data set has a large deviation from most of the points, this large deviation should be caught by the first couple of principal components.
  </p>
  <p>
   An important aspect here is that if I remove a point from the data set, I should run PCA again because the principal components are greatly influenced by outliers. The new principal components may lay in different directions.
  </p>
  <p>
   The first plot (red points are poi):
   <br/>
   <img alt="outl1" src="final_project/outlier_pca1_pca2_scatter.png" title="outlier"/>
  </p>
  <p>
   The point that has a value of over
   <mathjax>
    $5 *10^8$
   </mathjax>
   on the first principal component looks like an outlier. I print the key associated with the point:
  </p>
  <pre><code>"TOTAL"
</code></pre>
  <p>
   So this is clearly an outlier that comes from the spreadsheet from which this data was exported. We are looking to compare employers of Enron, so the total of all salaries, bonuses, etc, should not be in our data set.
  </p>
  <p>
   I remove it and repeat.
  </p>
  <p>
   The second plot:
   <br/>
   <img alt="outl1" src="final_project/outlier_pca1_pca2_scatter2.png" title="outlier"/>
  </p>
  <p>
   I will print the top two elements from the second component, and also the smallest one from the second component:
  </p>
  <pre><code>['BHATNAGAR SANJAY', 'LAY KENNETH L']
'HIRKO JOSEPH'
</code></pre>
  <p>
   Ok, so they are Enron employees, I’ll leave them in the data set.
  </p>
  <h2 id="feature-engineering">
   Feature Engineering
  </h2>
  <p>
   Except those features, we can also use the emails. I ran some experiments on text, to see what words a Decision Tree algorithm uses to distinguish between emails from two persons, Sara Shackelton and Chris Germany. Here is my output:
  </p>
  <h3 id="text-learning-experiment">
   Text learning experiment
  </h3>
  <pre><code>train acc: 1.0
test acc:  0.983333333333
Most important feature, and relative importance: cgermannsf : 0.973656480506

train acc: 1.0
test acc:  0.966666666667
Most important feature, and relative importance: sara : 0.923103212577

train acc: 1.0
test acc:  1.0
Most important feature, and relative importance: tjonesnsf : 0.51800776543

train acc: 1.0
test acc:  0.866666666667
Most important feature, and relative importance: chris : 0.437839234944

train acc: 1.0
test acc:  0.933333333333
Most important feature, and relative importance: shackleton : 0.321660482375
--------------------
top 5 most important words:
[u'cgermannsf', u'sara', u'tjonesnsf', u'chris', u'shackleton']
</code></pre>
  <p>
   It looks like all those are signature words. I’m concerned that for deciding whether a person is a poi or not, an algorithm using text may rely on previously known information. This decision tree can reach 100% accuracy, but it only looks at the signatures of the emails.
   <br/>
   In case of a poi vs non-poi classifier, the algorithm may rely on names of persons rather than more complex vocabulary to detect suspicious activity.
  </p>
  <p>
   I’ll try to engineer a feature from the data set available.
  </p>
  <h3 id="fraction-of-emails-to-and-from-poi">
   Fraction of emails to and from poi
  </h3>
  <p>
   If I plot the number of sent emails to poi vs number of emails received from poi, I get the following plot:
  </p>
  <p>
   <img alt="emails_poi_img" src="final_project/emails_poi.png" title="emails poi"/>
  </p>
  <p>
   There doesn’t seem to be a pattern here. I’ll try to compute the fraction of emails send to poi and received from poi rather than the number of emails.
  </p>
  <p>
   <img alt="fraction_emails_poi_img" src="final_project/fraction_emails_poi.png" title="fraction emails poi"/>
  </p>
  <p>
   This plot looks good. There’s not a very strong separation between poi and non-poi, but there is some separation. There are areas in this plot where there are only non-poi.
  </p>
  <h2 id="classifiers">
   Classifiers
  </h2>
  <h3 id="try-classifiers-out-of-the-box">
   Try Classifiers Out of the Box
  </h3>
  <p>
   First I’ll try a couple of classifiers out of the box. I’ll test the following classifiers:
  </p>
  <ul>
   <li>
    Decision Trees
   </li>
   <li>
    Ada Boost
   </li>
   <li>
    KNC
   </li>
   <li>
    Gaussian Naive Bayes
   </li>
   <li>
    Logistic Regression
   </li>
   <li>
    SVC
   </li>
  </ul>
  <p>
   The results are the following:
   <br/>
   <font face="mono">
    <br/>
    <strong>
     GaussianNB
    </strong>
    ()
   </font>
  </p>
  <pre><code>Accuracy: 0.83787   
Precision: 0.32524  
Recall: 0.20100 
F1: 0.24845 
F2: 0.21763

Total predictions: 15000    
True positives:  402    
False positives:  834   
False negatives: 1598   
True negatives: 12166
</code></pre>
  <p>
   Got a divide by zero when trying out:
   <br/>
   <strong>
    SVC
   </strong>
   (C=1.0, cache_size=200, class_weight=None, coef0=0.0,
   <br/>
   decision_function_shape=None, degree=3, gamma=’auto’, kernel=’rbf’,
   <br/>
   max_iter=-1, probability=False, random_state=None, shrinking=True,
   <br/>
   tol=0.001, verbose=False)
   <br/>
   Precision or recall may be undefined due to a lack of true positive predicitons.
  </p>
  <p>
   <strong>
    DecisionTreeClassifier
   </strong>
   (class_weight=None, criterion=’gini’, max_depth=None,
   <br/>
   max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
   <br/>
   min_samples_split=2, min_weight_fraction_leaf=0.0,
   <br/>
   presort=False, random_state=None, splitter=’best’)
  </p>
  <pre><code>Accuracy: 0.82813   
Precision: 0.35026
Recall: 0.33800
F1: 0.34402
F2: 0.34038

Total predictions: 15000
True positives:  676
False positives: 1254
False negatives: 1324
True negatives: 11746
</code></pre>
  <p>
   <strong>
    AdaBoostClassifier
   </strong>
   (algorithm=’SAMME.R’, base_estimator=None,
   <br/>
   learning_rate=1.0, n_estimators=50, random_state=None)
  </p>
  <pre><code>Accuracy: 0.84353
Precision: 0.38712
Recall: 0.29750
F1: 0.33644
F2: 0.31194

Total predictions: 15000
True positives:  595
False positives:  942
False negatives: 1405
True negatives: 12058
</code></pre>
  <p>
   <strong>
    KNeighborsClassifier
   </strong>
   (algorithm=’auto’, leaf_size=30, metric=’minkowski’,
   <br/>
   metric_params=None, n_jobs=1, n_neighbors=5, p=2,
   <br/>
   weights=’uniform’)
  </p>
  <pre><code>Accuracy: 0.88727   
Precision: 0.75537  
Recall: 0.22850 
F1: 0.35086 
F2: 0.26554

Total predictions: 15000    
True positives:  457    
False positives:  148   
False negatives: 1543   
True negatives: 12852
</code></pre>
  <p>
   <strong>
    LogisticRegression
   </strong>
   (C=1.0, class_weight=None, dual=False, fit_intercept=True,
   <br/>
   intercept_scaling=1, max_iter=100, multi_class=’ovr’, n_jobs=1,
   <br/>
   penalty=’l2’, random_state=None, solver=’liblinear’, tol=0.0001,
   <br/>
   verbose=0, warm_start=False)
  </p>
  <pre><code>Accuracy: 0.73460   
Precision: 0.10648  
Recall: 0.13400 
F1: 0.11866 
F2: 0.12741

Total predictions: 15000    
True positives:  268    
False positives: 2249   
False negatives: 1732   
True negatives: 10751
</code></pre>
  <p>
  </p>
  <p>
   I will use the
   <mathjax>
    $F_1$
   </mathjax>
   score to decide what algorithm I will chose for the next step. The
   <mathjax>
    $F_1$
   </mathjax>
   score combines precision and recall into one measure. The formula is the following:
  </p>
  <p>
   <mathjax>
    $$
F_1 = 2 \cdot \frac{P \cdot R}{P+R}
$$
   </mathjax>
  </p>
  <p>
   Where:
   <br/>
   <mathjax>
    $P$
   </mathjax>
   = precision
   <br/>
   <mathjax>
    $R$
   </mathjax>
   = recall
  </p>
  <p>
   This metric considers precision and recall as equaly important. There are other metrics that put more weight on either precision or recall (
   <mathjax>
    $F_2$
   </mathjax>
   puts more weight on precision).
  </p>
  <p>
   Using
   <mathjax>
    $F_1$
   </mathjax>
   score, the best performing algorithm is KNN followed by Decision Trees. Ada Boost is also very close to the performance of the Decision Tree algorithm.
  </p>
  <h3 id="tune-classifiers">
   Tune Classifiers
  </h3>
  <p>
   I’ll use GridCV to find the best tuning parameters. I’ll start with KNN
  </p>
  <p>
   A potential limitation of this algorithm in this case is the fact that we have a very small number of positive examples. Since the algorithm relies on nearest points, it may be difficult to obtain high recall. It will output negative for most of the times, since it has very few examples of positive pois. This can be solved using different weights for positive and negative classes.
  </p>
  <h4 id="knc">
   KNC
  </h4>
  <p>
   <font face="mono">
    <br/>
    <strong>
     KNeighborsClassifier
    </strong>
    (algorithm=’auto’, leaf_size=30, metric=’minkowski’,
    <br/>
    metric_params=None, n_jobs=1, n_neighbors=5, p=2,
    <br/>
    weights=’uniform’)
   </font>
  </p>
  <pre><code>Accuracy: 0.88727
Precision: 0.75537
Recall: 0.22850
F1: 0.35086
F2: 0.26554

Total predictions: 15000
True positives:  457
False positives:  148
False negatives: 1543
True negatives: 12852
</code></pre>
  <p>
  </p>
  <p>
   This looks the same as the KNC I had before.
  </p>
  <h4 id="decision-tree">
   Decision Tree
  </h4>
  <p>
   <font face="mono">
   </font>
  </p>
  <p>
   <strong>
    DecisionTreeClassifier
   </strong>
   (class_weight=None, criterion=’gini’, max_depth=None,
   <br/>
   max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
   <br/>
   min_samples_split=2, min_weight_fraction_leaf=0.0,
   <br/>
   presort=False, random_state=None, splitter=’best’)
  </p>
  <pre><code>Accuracy: 0.82573
Precision: 0.33893
Recall: 0.32300
F1: 0.33077
F2: 0.32607

Total predictions: 15000
True positives:  646
False positives: 1260
False negatives: 1354
True negatives: 11740
</code></pre>
  <p>
  </p>
  <p>
   The Decision Tree has better recall, but lower precision. The
   <mathjax>
    $F_1$
   </mathjax>
   score is higher than the score for K Neighbors Classifier. I would chose this classifier as the final one to use in this project.
  </p>
  <h3 id="features">
   Features
  </h3>
  <p>
   <strong>
    Testing the new features
   </strong>
  </p>
  <p>
   I will test the performance of the algorithm with and without the new features:
  </p>
  <p>
   <font face="mono">
    <br/>
    Selecting best features for Decision Tree
    <br/>
    Performance with all features
   </font>
  </p>
  <table>
   <thead>
    <tr>
     <th>
      Feature
     </th>
     <th>
      Importance
     </th>
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>
      bonus
     </td>
     <td>
      <code>
       0.397261173535
      </code>
     </td>
    </tr>
    <tr>
     <td>
      expenses
     </td>
     <td>
      <code>
       0.23848965585
      </code>
     </td>
    </tr>
    <tr>
     <td>
      restricted_stock
     </td>
     <td>
      <code>
       0.121017988532
      </code>
     </td>
    </tr>
    <tr>
     <td>
      total_payments
     </td>
     <td>
      <code>
       0.10882132898
      </code>
     </td>
    </tr>
    <tr>
     <td>
      other
     </td>
     <td>
      <code>
       0.106100795756
      </code>
     </td>
    </tr>
    <tr>
     <td>
      fraction_to_poi
     </td>
     <td>
      <code>
       0.0283090573472
      </code>
     </td>
    </tr>
    <tr>
     <td>
      total_stock_value
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      exercised_stock_options
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      salary
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      to_messages
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      shared_receipt_with_poi
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      from_messages
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      from_poi_to_this_person
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      from_this_person_to_poi
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      fraction_from_poi
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   DecisionTreeClassifier(class_weight=None, criterion=’gini’, max_depth=None,
   <br/>
   max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
   <br/>
   min_samples_split=2, min_weight_fraction_leaf=0.0,
   <br/>
   presort=False, random_state=None, splitter=’best’)
  </p>
  <pre><code>Accuracy: 0.82527
Precision: 0.34085
Recall: 0.33250
F1: 0.33662
F2: 0.33414

Total predictions: 15000
True positives:  665
False positives: 1286
False negatives: 1335
True negatives: 11714
</code></pre>
  <hr/>
  <p>
   <strong>
    Performance without ‘fraction_from_poi’ and ‘fraction_to_poi’
   </strong>
  </p>
  <p>
   Selecting best features for Decision Tree
  </p>
  <table>
   <thead>
    <tr>
     <th>
      Feature
     </th>
     <th>
      Importance
     </th>
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>
      bonus
     </td>
     <td>
      <code>
       0.397261173535
      </code>
     </td>
    </tr>
    <tr>
     <td>
      expenses
     </td>
     <td>
      <code>
       0.23848965585
      </code>
     </td>
    </tr>
    <tr>
     <td>
      total_payments
     </td>
     <td>
      <code>
       0.10882132898
      </code>
     </td>
    </tr>
    <tr>
     <td>
      other
     </td>
     <td>
      <code>
       0.106100795756
      </code>
     </td>
    </tr>
    <tr>
     <td>
      from_poi_to_this_person
     </td>
     <td>
      <code>
       0.0757862826828
      </code>
     </td>
    </tr>
    <tr>
     <td>
      restricted_stock
     </td>
     <td>
      <code>
       0.0620731020005
      </code>
     </td>
    </tr>
    <tr>
     <td>
      from_this_person_to_poi
     </td>
     <td>
      <code>
       0.0114676611954
      </code>
     </td>
    </tr>
    <tr>
     <td>
      total_stock_value
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      exercised_stock_options
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      salary
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      to_messages
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      shared_receipt_with_poi
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      from_messages
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   DecisionTreeClassifier(class_weight=None, criterion=’gini’, max_depth=None,
   <br/>
   max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
   <br/>
   min_samples_split=2, min_weight_fraction_leaf=0.0,
   <br/>
   presort=False, random_state=None, splitter=’best’)
  </p>
  <pre><code>Accuracy: 0.80233
Precision: 0.25320
Recall: 0.24750
F1: 0.25032
F2: 0.24862

Total predictions: 15000
True positives:  495
False positives: 1460
False negatives: 1505
True negatives: 11540
</code></pre>
  <p>
  </p>
  <p>
   So those features clearly affect the performance of the Decision Tree. At least
   <code>
    fraction_to_poi
   </code>
   should be included in the algorithm.
  </p>
  <p>
   Out of the features that I selected in the begining, I’ll select now only the most useful ones, based on the importance assigned by the Decision Tree algorithm.
  </p>
  <p>
   I decided to implement my own selection of features because in case of SelectKBest function, I don’t know what the K should be (although it’s true I can find this out, but I’d like to write code to figure this out, rather than manually inspect and code with the number of features I found). The same is true in case of SelectPercentile. I don’t know what percentage of features are useful. But I can look at the importance of features, and select all features that contrubute with at least 1% (in the case of decision trees, this means select features that are used to distinguish at least 1% of the data).
   <br/>
   I performed this selection, and ended up with only a handful of features:
  </p>
  <p>
   For final classifier, will pick the best of:
  </p>
  <table>
   <thead>
    <tr>
     <th>
      Feature
     </th>
     <th>
      Importance
     </th>
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>
      <font color="green">
       bonus
      </font>
     </td>
     <td>
      <code>
       0.397261173535
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       restricted_stock
      </font>
     </td>
     <td>
      <code>
       0.168173897756
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       other
      </font>
     </td>
     <td>
      <code>
       0.132625994695
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       total_payments
      </font>
     </td>
     <td>
      <code>
       0.10882132898
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       expenses
      </font>
     </td>
     <td>
      <code>
       0.105863661155
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       from_poi_to_this_person
      </font>
     </td>
     <td>
      <code>
       0.0589448865311
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="green">
       fraction_to_poi
      </font>
     </td>
     <td>
      <code>
       0.0283090573472
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       total_stock_value
      </font>
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       exercised_stock_options
      </font>
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       salary
      </font>
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       to_messages
      </font>
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       shared_receipt_with_poi
      </font>
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       from_messages
      </font>
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       from_this_person_to_poi
      </font>
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
    <tr>
     <td>
      <font color="red">
       fraction_from_poi
      </font>
     </td>
     <td>
      <code>
       0.0
      </code>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   So when I test the algorithm only with the features highlighted in green I get the following result:
   <br/>
   <font face="mono">
    <br/>
    Feature importances for final classifier
   </font>
  </p>
  <table>
   <thead>
    <tr>
     <th>
      Feature
     </th>
     <th>
      Importance
     </th>
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>
      total_payments
     </td>
     <td>
      <code>
       0.315958946149
      </code>
     </td>
    </tr>
    <tr>
     <td>
      restricted_stock
     </td>
     <td>
      <code>
       0.224691893457
      </code>
     </td>
    </tr>
    <tr>
     <td>
      exercised_stock_options
     </td>
     <td>
      <code>
       0.171111111111
      </code>
     </td>
    </tr>
    <tr>
     <td>
      total_stock_value
     </td>
     <td>
      <code>
       0.1322681593
      </code>
     </td>
    </tr>
    <tr>
     <td>
      salary
     </td>
     <td>
      <code>
       0.100088785949
      </code>
     </td>
    </tr>
    <tr>
     <td>
      expenses
     </td>
     <td>
      <code>
       0.055881104034
      </code>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   DecisionTreeClassifier(class_weight=None, criterion=’gini’, max_depth=None,
   <br/>
   max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
   <br/>
   min_samples_split=2, min_weight_fraction_leaf=0.0,
   <br/>
   presort=False, random_state=None, splitter=’best’)
  </p>
  <pre><code>Accuracy: 0.82833
Precision: 0.35111
Recall: 0.33900
F1: 0.34495
F2: 0.34136

Total predictions: 15000
True positives:  678
False positives: 1253
False negatives: 1322
True negatives: 11747
</code></pre>
  <p>
  </p>
  <p>
   So we can see that the accuracy is about the same. I think we can use this subset of features to investigate.
  </p>
  <p>
   <strong>
    Note:
   </strong>
   For Decision Trees scaling is not necesary. Decision trees look for the best split for one variable at a time. If the variable is scaled, the split point will be at a different location (different numerical value), but it won’t make any difference for the classification process.
  </p>
  <p>
   I would like to point out that some features that were provided in the data set may be responsible for information leakage. Thise features are
   <code>
    from_poi_to_this_person
   </code>
   ,
   <code>
    from_this_person_to_poi
   </code>
   and
   <code>
    shared_receipt_with_poi
   </code>
   . Those values are computed using the whole data set. In other words, in order to find this information, the values of those variables, we needed to know who is a poi. In orded to compute those numbers, the whole data set was used, both the train set and the test set. In the real world though, we may identify a couple of pois (a small number, 2-3) and then compute those features using only the pois that we identified. In that case, the features will have less predictive power, because we won’t count shared emails or receipts between all pois, only between the ones we identified.
  </p>
  <h3 id="validation">
   Validation
  </h3>
  <p>
   Validation is the process of determining the performance of the algorithm. For validation it is necesary to split the available data in training and test data. The algorithm will be trained on the training data only, and it never sees the corect results for test data. We then apply the classification algorithm on the test data, and compare it with the real values.
  </p>
  <p>
   In order to validate an algorithm we need an objective way to asses its performance. We have to use some metrics like precision, recall,
   <mathjax>
    $F_1$
   </mathjax>
   score,
   <mathjax>
    $F_2$
   </mathjax>
   score.
  </p>
  <h3 id="metrics">
   Metrics
  </h3>
  <p>
   This particular project has some limitations because the data set is very small. As I showed in the introduction, there are 18 pois out of 145 (after I removed the “TOTAL” there are 145 points left in the data set).
  </p>
  <p>
   Because there are unbalanced examples (a lot of non-pois and just a couple of pois), it is necesary to use
   <strong>
    precision
   </strong>
   and
   <strong>
    recall
   </strong>
   to asses the performance of the algorithm.
   <br/>
   Some algorithms favor precision over recall (like KNC), while others can be tuned to find a balance point in-between.
  </p>
  <p>
   <strong>
    Precision
   </strong>
   measures the ratio of corectly identified events (persons of interest in this case), over the number of events reported positive by the algorithm. For example, KNC has high precision, this is because KNC clasifies a point based on the similarity with other points. But because there are a lot of negative examples in the data set, the clasifier is more likely to find examples of negative points (non-poi). On the other hand, when it does report a poi, this point is most likely in the center of other pois, so it’s very likely a poi. An algorithm with high precision might miss edge cases, but when it does output a point as a poi, it is very likely a poi.
  </p>
  <p>
   <mathjax>
    $$
P = \frac{TP}{TP + FP}
$$
   </mathjax>
  </p>
  <p>
   <mathjax>
    $P$
   </mathjax>
   = precision
   <br/>
   <mathjax>
    $TP$
   </mathjax>
   = true positives
   <br/>
   <mathjax>
    $FP$
   </mathjax>
   = false positives
  </p>
  <p>
   <strong>
    Recall
   </strong>
   measures the ratio of corectly identified points (pois in this case) out of all positive points. If an algorithm has high recall, if there is a poi in the data set, the algorithm is very likely to find it. On the other hand, it may output a lot of false positive. Note that it is very easy to create an algorithm with recall=1, simply output true for every element.
  </p>
  <p>
   <mathjax>
    $$
R = \frac{TP}{TP + FN}
$$
   </mathjax>
  </p>
  <p>
   <mathjax>
    $R$
   </mathjax>
   = recall
   <br/>
   <mathjax>
    $TP$
   </mathjax>
   = true positives
   <br/>
   <mathjax>
    $FN$
   </mathjax>
   = false negatives
  </p>
  <p>
   I also consider
   <mathjax>
    $F_1$
   </mathjax>
   and
   <mathjax>
    $F_2$
   </mathjax>
   scores. Those metrics simply combine precision and recall in a single number.
   <mathjax>
    $F_1$
   </mathjax>
   aims at finding the right balance between precision and recall, while
   <mathjax>
    $F_2$
   </mathjax>
   places more weight on recall.
  </p>
  <p>
   <mathjax>
    $$
F_1 = 2 \cdot \frac{P \cdot R}{P+R}
$$
   </mathjax>
   <br/>
   <mathjax>
    $$
F_2 = 5 \cdot \frac{P \cdot R}{4P+R}
$$
   </mathjax>
  </p>
  <p>
   Where:
   <br/>
   <mathjax>
    $P$
   </mathjax>
   = precision
   <br/>
   <mathjax>
    $R$
   </mathjax>
   = recall
  </p>
  <h2 id="conclusion">
   Conclusion
  </h2>
  <p>
   In this project I showed how Machine Learning could be used to identify persons involved in fraud using financial data and some agregated data about email activity. This particular data set is pretty small, so the results may not be great, but even so, the final classifier has 0.82 accuracy, with precision and recall about 0.33. I believe Machine Learning can be used for this application to obtain some insight into the fraudulent activity. Also, Machine Learning can be used with similar information about employees to asses engagement level of employees, or probability that they will switch jobs.
  </p>
  <script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/highlight.min.js">
  </script>
  <script>
   hljs.initHighlightingOnLoad();
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
  </script>
  <script type="text/javascript">
   MathJax.Hub.Config({"showProcessingMessages" : false,"messageStyle" : "none","tex2jax": { inlineMath: [ [ "$", "$" ] ] }});
  </script>
 </body>
</html>